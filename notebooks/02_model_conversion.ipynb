{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPmidP1vxRGOIn6BfuDQI0I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Phase 2: Model Conversion"],"metadata":{"id":"E06fSXYcHF_M"}},{"cell_type":"markdown","source":["This notebook converts the custom trained .h5 models into edge-optimized formats.\n","\n","*   TensorFlow.js format (.json + .bin) for use in a Progressive Web App (PWA)\n","*   TensorFlow Lite format (.tflite) for use in mobile apps\n","\n","This ensures models are ready for execution on-device, enabling real-time predictions without server calls.\n"],"metadata":{"id":"LHSF5NmIGxRg"}},{"cell_type":"markdown","source":["**1. Setting up the environment**"],"metadata":{"id":"0eSUIhU_DFUj"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxObgCxAC0kx","executionInfo":{"status":"ok","timestamp":1754214185680,"user_tz":-60,"elapsed":9612,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"4e5126e1-89b9-4ab7-dd7e-1c10e89741eb","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/89.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/53.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","xarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n","google-cloud-bigquery 3.35.1 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n","db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip install -q tensorflow tensorflowjs"]},{"cell_type":"code","source":["import os\n","import tensorflow as tf\n","import tensorflowjs as tfjs\n","from tensorflow.keras.models import load_model\n","import numpy as np\n","import pandas as pd\n","import json\n","import os"],"metadata":{"id":"l2qnh0DKDIVt","executionInfo":{"status":"ok","timestamp":1754217597616,"user_tz":-60,"elapsed":41,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# define paths\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","BASE_PATH = \"/content/drive/My Drive/Edge_AI_Project/models\"\n","H5_PATH = os.path.join(BASE_PATH, \"saved_models\")\n","TFJS_PATH = os.path.join(BASE_PATH, \"tfjs_models\")\n","TFLITE_PATH = os.path.join(BASE_PATH, \"tflite_models\")\n","LOG_PATH = os.path.join(BASE_PATH, \"conversion_logs\")\n","\n","# Clean up and recreate directories\n","import shutil\n","\n","# Remove existing converted models to start fresh\n","if os.path.exists(TFJS_PATH):\n","    shutil.rmtree(TFJS_PATH)\n","if os.path.exists(TFLITE_PATH):\n","    shutil.rmtree(TFLITE_PATH)\n","\n","os.makedirs(TFJS_PATH, exist_ok=True)\n","os.makedirs(TFLITE_PATH, exist_ok=True)\n","os.makedirs(LOG_PATH, exist_ok=True)\n","\n","print(\"‚úÖ Directories cleaned and recreated\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsJROdhkQD_4","executionInfo":{"status":"ok","timestamp":1754216677851,"user_tz":-60,"elapsed":1677,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"b750f31b-4025-46d1-c3a5-f53418b64efe"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","‚úÖ Directories cleaned and recreated\n"]}]},{"cell_type":"markdown","source":["**2. Model Conversion Functions**"],"metadata":{"id":"4l15Xw9uDU-n"}},{"cell_type":"code","source":["def convert_to_tfjs_simple(h5_model_path, output_dir, model_name):\n","    \"\"\"\n","    Simple TensorFlow.js conversion without model reconstruction\n","    \"\"\"\n","    print(f\"\\nüîÑ Converting {model_name} to TensorFlow.js...\")\n","\n","    # Load original model\n","    model = load_model(h5_model_path)\n","    print(f\"   Loaded model: {model.input_shape} -> {model.output_shape}\")\n","\n","    # Test the model works\n","    if model.input_shape[1:] == (224, 224, 3):\n","        test_input = np.random.random((1, 224, 224, 3)).astype(np.float32)\n","    elif model.input_shape[1:] == (48, 48, 1):\n","        test_input = np.random.random((1, 48, 48, 1)).astype(np.float32)\n","    else:\n","        raise ValueError(f\"Unexpected input shape: {model.input_shape}\")\n","\n","    test_output = model.predict(test_input, verbose=0)\n","    print(f\"   Model test successful - Output shape: {test_output.shape}\")\n","\n","    # Convert to TensorFlow.js with UPDATED API\n","    print(f\"   Converting to TensorFlow.js format...\")\n","    tfjs.converters.save_keras_model(model, output_dir)\n","\n","    print(f\"‚úÖ Successfully converted {model_name} to TensorFlow.js\")\n","\n","    # Verify the conversion\n","    model_files = os.listdir(output_dir)\n","    print(f\"   Generated files: {model_files}\")\n","\n","    return model\n","\n","def convert_to_tflite_simple(h5_model_path, output_path, model_name):\n","    \"\"\"\n","    Simple TensorFlow Lite conversion\n","    \"\"\"\n","    print(f\"\\nüîÑ Converting {model_name} to TensorFlow Lite...\")\n","\n","    model = load_model(h5_model_path)\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]  # Post-training quantization\n","    tflite_model = converter.convert()\n","\n","    with open(output_path, 'wb') as f:\n","        f.write(tflite_model)\n","\n","    print(f\"‚úÖ Successfully converted {model_name} to TensorFlow Lite\")\n"],"metadata":{"id":"fdKe7zyqQbG8","executionInfo":{"status":"ok","timestamp":1754216682759,"user_tz":-60,"elapsed":5,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["**3. Model configuration**"],"metadata":{"id":"r2c8mvjXVupa"}},{"cell_type":"code","source":["models = {\n","    \"age\": {\n","        \"filename\": \"age_model.h5\",\n","        \"input_shape\": (224, 224, 3)\n","    },\n","    \"gender\": {\n","        \"filename\": \"gender_model.h5\",\n","        \"input_shape\": (224, 224, 3)\n","    },\n","    \"emotion\": {\n","        \"filename\": \"emotion_model.h5\",\n","        \"input_shape\": (48, 48, 1)\n","    }\n","}"],"metadata":{"id":"pUN3BXkAVxfT","executionInfo":{"status":"ok","timestamp":1754216690256,"user_tz":-60,"elapsed":5,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["**4. Conversion and Logging Loop**"],"metadata":{"id":"cYXEi1RNDiU4"}},{"cell_type":"code","source":["log_data = []\n","\n","print(\"Starting model conversion process...\\n\")\n","\n","for name, config in models.items():\n","    print(f\"{'='*60}\")\n","    print(f\"üîÑ Processing {name.upper()} model...\")\n","    print(f\"{'='*60}\")\n","\n","    h5_path = os.path.join(H5_PATH, config[\"filename\"])\n","    tfjs_dir = os.path.join(TFJS_PATH, name)\n","    tflite_path = os.path.join(TFLITE_PATH, f\"{name}.tflite\")\n","\n","    try:\n","        # Convert to TensorFlow.js\n","        model = convert_to_tfjs_simple(h5_path, tfjs_dir, name)\n","\n","        # Convert to TFLite\n","        convert_to_tflite_simple(h5_path, tflite_path, name)\n","\n","        # Calculate file sizes\n","        tfjs_size = sum(os.path.getsize(os.path.join(tfjs_dir, f)) for f in os.listdir(tfjs_dir))\n","        tflite_size = os.path.getsize(tflite_path)\n","        h5_size = os.path.getsize(h5_path)\n","\n","        # Log the results\n","        log_data.append({\n","            \"Model\": name.capitalize(),\n","            \"Input Shape\": config[\"input_shape\"],\n","            \".h5 Size (KB)\": round(h5_size / 1024, 2),\n","            \"TF.js Size (KB)\": round(tfjs_size / 1024, 2),\n","            \".tflite Size (KB)\": round(tflite_size / 1024, 2),\n","            \"Model Layers\": len(model.layers),\n","            \"Output .tflite\": tflite_path,\n","            \"Output TF.js Dir\": tfjs_dir\n","        })\n","\n","        print(f\"‚úÖ {name.upper()} model conversion completed successfully!\\n\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå Error processing {name} model: {str(e)}\")\n","        import traceback\n","        traceback.print_exc()\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"Model conversion completed!\")\n","print(\"=\"*70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ESfO1ZMGQ4IH","executionInfo":{"status":"ok","timestamp":1754216730640,"user_tz":-60,"elapsed":39022,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"d15af7cd-1855-47e6-a02a-35916234bb19"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting model conversion process...\n","\n","============================================================\n","üîÑ Processing AGE model...\n","============================================================\n","\n","üîÑ Converting age to TensorFlow.js...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["   Loaded model: (None, 224, 224, 3) -> (None, 1)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78df89b34a40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["   Model test successful - Output shape: (1, 1)\n","   Converting to TensorFlow.js format...\n","failed to lookup keras version from the file,\n","    this is likely a weight only file\n","‚úÖ Successfully converted age to TensorFlow.js\n","   Generated files: ['group1-shard1of3.bin', 'group1-shard2of3.bin', 'group1-shard3of3.bin', 'model.json']\n","\n","üîÑ Converting age to TensorFlow Lite...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmpvrsb2xmo'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer')\n","Output Type:\n","  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n","Captures:\n","  132901495619408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495616720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495616528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495616912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495618448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495614032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495613456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495613072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495614800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495617680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495614992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495615568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495615184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495619024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495617104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901495613648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494916496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494916880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494916688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494915152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494918032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494918416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494918800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494918608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494915920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494919952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494920336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494920720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494920528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494915536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494921872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494922256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494922640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494922448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494917648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494923792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494924176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494924560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494924368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494919568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494925712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494926096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494926480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494926288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494921488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494927632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494928016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494928400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494928208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494923408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494929552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494929936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494930320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494930128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494925328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494927248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502992848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502993424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494929168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901494928784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502994384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502994768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502995152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502994960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502993616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502996304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502996688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502997072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502996880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502992656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502998224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502998608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502998992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502998800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502994000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503000144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503000528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503000912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503000720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502995920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503002064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503002448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503002832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503002640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502997840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503003984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503004368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503004752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503004560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901502999760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503005904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503006288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503006672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503006480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503001680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503007824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503007440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503007056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503008400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503003600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503005520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503387024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503387408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503387216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503385680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503388560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503388944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503389328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503389136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503386448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503390480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503390864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503391248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503391056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503386064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503392400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503392784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503393168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503392976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503388176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503394320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503394704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503395088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503394896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503390096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503396240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503396624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503397008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503396816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503392016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503398160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503398544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503398928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503398736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503393936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503400080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503400464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503400848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503400656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503395856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503397776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503467984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503468560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503399696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503399312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503469520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503469904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503470288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503470096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503468752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503471440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503471824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503472208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503472016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503467792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503473360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503473744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503474128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503473936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503469136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503475280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503475664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503476048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503475856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503471056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503477200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503477584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503477968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503477776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503472976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503479120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503479504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503479888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503479696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503474896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503481040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503481424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503481808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503481616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503476816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503482960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503482576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503482192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503483536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503478736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503480656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503780240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503780624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503780432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503779472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503781776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503782160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503782544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503782352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503779664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503783696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503784080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503784464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503784272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503778896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503785616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503786000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503786384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503786192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503781392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503787536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503787920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503788304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503788112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503783312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503789456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503789840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503790224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503790032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503785232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503791376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503791760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503792144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503791952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503787152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503793296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503793680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503794064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503793872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503789072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503790992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709807888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709808656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503792912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901503792528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709809616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709810000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709810384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709810192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709808848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709811536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709811920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709812304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709812112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709807696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709813456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709813840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709814224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709814032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709809232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709815376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709815760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709816144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709815952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709811152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709817296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709817680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709818064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709817872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709813072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709819216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709819600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709819984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709819792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709814992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709821136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901709821712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","‚úÖ Successfully converted age to TensorFlow Lite\n","‚úÖ AGE model conversion completed successfully!\n","\n","============================================================\n","üîÑ Processing GENDER model...\n","============================================================\n","\n","üîÑ Converting gender to TensorFlow.js...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["   Loaded model: (None, 224, 224, 3) -> (None, 1)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78df8841eac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["   Model test successful - Output shape: (1, 1)\n","   Converting to TensorFlow.js format...\n","failed to lookup keras version from the file,\n","    this is likely a weight only file\n","‚úÖ Successfully converted gender to TensorFlow.js\n","   Generated files: ['group1-shard1of3.bin', 'group1-shard2of3.bin', 'group1-shard3of3.bin', 'model.json']\n","\n","üîÑ Converting gender to TensorFlow Lite...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmppmrjkswi'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer')\n","Output Type:\n","  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n","Captures:\n","  132901459148240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901459142672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901459148048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901459147088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901459148432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901459148624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457576976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457576016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901459145936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457576208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457578320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457578704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457579088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457578896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457576400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457580240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457580624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457581008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457580816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457576784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457582160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457582544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457582928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457582736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457577936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457584080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457584464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457584848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457584656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457579856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457586000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457586384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457586768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457586576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457581776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457587920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457588304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457588688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457588496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457583696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457589840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457590224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457590608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457590416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457585616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457591760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457577168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457592144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457591952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457589456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457773968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457776656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457775696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457774544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457775312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457777616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457778000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457778576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457778384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457776080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457779536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457779920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457773008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457773584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457776848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457774352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457780112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457780496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457780304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457777232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457781648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457782032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457782416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457782224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457779152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457783568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457783952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457784336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457784144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457774928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457785488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457785872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457786256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457786064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457781264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457787408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457787792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457788560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457787984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457783184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457786640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455856272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455856848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901457787024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455855696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455858000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455858384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455858768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455858576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455855888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455859920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455860304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455860688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455860496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455856464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455861840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455862224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455862608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455862416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455857616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455863760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455864144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455864528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455864336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455859536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455865680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455866064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455866448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455866256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455861456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455867600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455867984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455868368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455868176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455863376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455869520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455869904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455870288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455870096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455865296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455871440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455856080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455871824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455871632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901455869136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456053648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456054032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456054416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456054224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456052496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456055568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456055952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456056336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456056144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456052304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456057488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456057872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456058256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456058064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456053072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456059408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456059792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456060176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456059984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456055184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456061328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456061712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456062096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456061904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456057104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456063248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456063632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456064016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456063824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456059024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456065168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456065552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456065936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456065744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456060944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456067088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456067472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456068240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456067664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456062864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456066320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456248912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456250064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456066704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456249872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456251216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456251600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456251984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456251792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456249680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456253136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456253520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456253904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456253712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456249104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456255056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456255440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456255824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456255632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456250832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456256976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456257360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456257744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456257552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456252752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456258896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456259280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456259664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456259472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456254672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456260816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456261200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456261584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456261392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456256592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456262736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456263120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456263504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456263312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456258512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456264656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456249296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456265040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456264848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456262352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456445904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456447248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456447632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456447440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456446096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456448784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456449168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456449552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456449360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456446672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456450704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456451088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456451472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456451280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456446864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456452624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456453008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456453392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456453200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456448400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456454544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456454928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456455312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456455120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456450320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456456464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456456848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456457232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456457040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456452240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456458384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456458768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456459152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456458960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456454160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456460304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456460688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456461456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456460880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456456080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456459536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901456459920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["‚úÖ Successfully converted gender to TensorFlow Lite\n","‚úÖ GENDER model conversion completed successfully!\n","\n","============================================================\n","üîÑ Processing EMOTION model...\n","============================================================\n","\n","üîÑ Converting emotion to TensorFlow.js...\n","   Loaded model: (None, 48, 48, 1) -> (None, 1)\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"output_type":"stream","name":"stdout","text":["   Model test successful - Output shape: (1, 1)\n","   Converting to TensorFlow.js format...\n","failed to lookup keras version from the file,\n","    this is likely a weight only file\n","‚úÖ Successfully converted emotion to TensorFlow.js\n","   Generated files: ['group1-shard1of3.bin', 'group1-shard2of3.bin', 'group1-shard3of3.bin', 'model.json']\n","\n","üîÑ Converting emotion to TensorFlow Lite...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Saved artifact at '/tmp/tmp397eflyp'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name='input_layer_1')\n","Output Type:\n","  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n","Captures:\n","  132901462973648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901462982096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482778256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482788048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482784208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482787472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482778832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482790544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482782672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482783632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482786320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482779984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901462981712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482787664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482785552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  132901482780368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","‚úÖ Successfully converted emotion to TensorFlow Lite\n","‚úÖ EMOTION model conversion completed successfully!\n","\n","\n","======================================================================\n","Model conversion completed!\n","======================================================================\n"]}]},{"cell_type":"markdown","source":["**5. Save conversion logs**"],"metadata":{"id":"CHx0fyOeEC5y"}},{"cell_type":"code","source":["if log_data:\n","    df = pd.DataFrame(log_data)\n","    log_file = os.path.join(LOG_PATH, \"simple_conversion_summary.csv\")\n","    df.to_csv(log_file, index=False)\n","\n","    print(f\"\\nüìä Conversion Summary:\")\n","    print(df.to_string(index=False))\n","    print(f\"\\nüíæ Log saved to: {log_file}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wZMAP7G5SBKe","executionInfo":{"status":"ok","timestamp":1754216746027,"user_tz":-60,"elapsed":13,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"70a60415-9348-49a4-c065-ed207dab23e6"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üìä Conversion Summary:\n","  Model   Input Shape  .h5 Size (KB)  TF.js Size (KB)  .tflite Size (KB)  Model Layers                                                              Output .tflite                                                   Output TF.js Dir\n","    Age (224, 224, 3)       26885.20          8979.97            2443.16           156     /content/drive/My Drive/Edge_AI_Project/models/tflite_models/age.tflite     /content/drive/My Drive/Edge_AI_Project/models/tfjs_models/age\n"," Gender (224, 224, 3)       26885.20          8979.97            2443.16           156  /content/drive/My Drive/Edge_AI_Project/models/tflite_models/gender.tflite  /content/drive/My Drive/Edge_AI_Project/models/tfjs_models/gender\n","Emotion   (48, 48, 1)       25666.21          8548.44            2142.49             9 /content/drive/My Drive/Edge_AI_Project/models/tflite_models/emotion.tflite /content/drive/My Drive/Edge_AI_Project/models/tfjs_models/emotion\n","\n","üíæ Log saved to: /content/drive/My Drive/Edge_AI_Project/models/conversion_logs/simple_conversion_summary.csv\n"]}]},{"cell_type":"markdown","source":["**6. Verification**"],"metadata":{"id":"U8cX4UJlSUzq"}},{"cell_type":"code","source":["print(f\"\\n Verification:\")\n","print(\"Checking if model.json files were created correctly...\")\n","\n","for name in models.keys():\n","    tfjs_dir = os.path.join(TFJS_PATH, name)\n","    model_json_path = os.path.join(tfjs_dir, \"model.json\")\n","\n","    if os.path.exists(model_json_path):\n","        print(f\"   ‚úÖ {name}: model.json exists\")\n","\n","        # Check file size\n","        json_size = os.path.getsize(model_json_path)\n","        if json_size > 1000:  # Should be at least 1KB\n","            print(f\"   ‚úÖ {name}: model.json has reasonable size ({json_size} bytes)\")\n","        else:\n","            print(f\"   ‚ö†Ô∏è  {name}: model.json seems too small ({json_size} bytes)\")\n","    else:\n","        print(f\"   ‚ùå {name}: model.json not found\")\n","\n","print(f\"\\n Verification CompleteE!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u8ZoRzqxSYpp","executionInfo":{"status":"ok","timestamp":1754216747697,"user_tz":-60,"elapsed":14,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"939b1411-fbc8-460d-e302-5f3a79463fbf"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," Verification:\n","Checking if model.json files were created correctly...\n","   ‚úÖ age: model.json exists\n","   ‚úÖ age: model.json has reasonable size (158430 bytes)\n","   ‚úÖ gender: model.json exists\n","   ‚úÖ gender: model.json has reasonable size (158430 bytes)\n","   ‚úÖ emotion: model.json exists\n","   ‚úÖ emotion: model.json has reasonable size (9148 bytes)\n","\n"," Verification CompleteE!\n"]}]},{"cell_type":"markdown","source":["Resolving issue with input shape information"],"metadata":{"id":"LxxjYatGjXuV"}},{"cell_type":"code","source":["# Add missing input shape information that TensorFlow.js needs\n","\n","# FINAL DEFINITIVE FIX - Replace Python None with JSON null\n","import json\n","import os\n","\n","BASE_PATH = \"/content/drive/My Drive/Edge_AI_Project/models/tfjs_models\"\n","\n","def fix_none_to_null(model_name):\n","    \"\"\"\n","    Replace all Python None values with JSON null values\n","    \"\"\"\n","    model_json_path = os.path.join(BASE_PATH, model_name, 'model.json')\n","\n","    print(f\"üîß Fixing {model_name} - Converting None to null...\")\n","\n","    # Read the file as text first\n","    with open(model_json_path, 'r') as f:\n","        content = f.read()\n","\n","    # Count None occurrences before fix\n","    none_count = content.count('None')\n","    print(f\"   Found {none_count} instances of 'None'\")\n","\n","    # Replace Python None with JSON null\n","    fixed_content = content.replace('None', 'null')\n","\n","    # Also fix Python booleans if they exist\n","    fixed_content = fixed_content.replace('True', 'true')\n","    fixed_content = fixed_content.replace('False', 'false')\n","\n","    # Write back the fixed content\n","    with open(model_json_path, 'w') as f:\n","        f.write(fixed_content)\n","\n","    # Verify the fix\n","    with open(model_json_path, 'r') as f:\n","        new_content = f.read()\n","\n","    none_count_after = new_content.count('None')\n","    null_count_after = new_content.count('null')\n","\n","    print(f\"   ‚úÖ After fix: {none_count_after} 'None', {null_count_after} 'null'\")\n","\n","    # Verify it's valid JSON\n","    try:\n","        with open(model_json_path, 'r') as f:\n","            json.load(f)\n","        print(f\"   ‚úÖ Valid JSON format confirmed\")\n","        return True\n","    except json.JSONDecodeError as e:\n","        print(f\"   ‚ùå JSON validation failed: {e}\")\n","        return False\n","\n","print(\"üöÄ FINAL FIX: Converting Python None to JSON null\")\n","print(\"=\"*60)\n","\n","success_count = 0\n","for model_name in ['age', 'gender', 'emotion']:\n","    if fix_none_to_null(model_name):\n","        success_count += 1\n","    print()\n","\n","print(f\"üéâ COMPLETED: {success_count}/3 models fixed successfully!\")\n","\n","# Final verification\n","print(\"\\nüîç FINAL VERIFICATION:\")\n","for model_name in ['age', 'gender', 'emotion']:\n","    model_json_path = os.path.join(BASE_PATH, model_name, 'model.json')\n","\n","    with open(model_json_path, 'r') as f:\n","        content = f.read()\n","\n","    none_count = content.count('None')\n","    null_count = content.count('null')\n","\n","    if none_count == 0 and null_count > 0:\n","        print(f\"   ‚úÖ {model_name}: Clean JSON (0 'None', {null_count} 'null')\")\n","    else:\n","        print(f\"   ‚ùå {model_name}: Still has issues ({none_count} 'None', {null_count} 'null')\")\n","\n","print(f\"\\n‚úÖ All models should now have proper JSON null values!\")\n","print(f\"üì• Download these fixed models and replace your GitHub files.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1Egv2vCgrzS","executionInfo":{"status":"ok","timestamp":1754219251053,"user_tz":-60,"elapsed":77,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"cbf4183c-ef14-4dfd-dfae-a7bb62ca9427"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ FINAL FIX: Converting Python None to JSON null\n","============================================================\n","üîß Fixing age - Converting None to null...\n","   Found 0 instances of 'None'\n","   ‚úÖ After fix: 0 'None', 1222 'null'\n","   ‚úÖ Valid JSON format confirmed\n","\n","üîß Fixing gender - Converting None to null...\n","   Found 0 instances of 'None'\n","   ‚úÖ After fix: 0 'None', 1222 'null'\n","   ‚úÖ Valid JSON format confirmed\n","\n","üîß Fixing emotion - Converting None to null...\n","   Found 0 instances of 'None'\n","   ‚úÖ After fix: 0 'None', 75 'null'\n","   ‚úÖ Valid JSON format confirmed\n","\n","üéâ COMPLETED: 3/3 models fixed successfully!\n","\n","üîç FINAL VERIFICATION:\n","   ‚úÖ age: Clean JSON (0 'None', 1222 'null')\n","   ‚úÖ gender: Clean JSON (0 'None', 1222 'null')\n","   ‚úÖ emotion: Clean JSON (0 'None', 75 'null')\n","\n","‚úÖ All models should now have proper JSON null values!\n","üì• Download these fixed models and replace your GitHub files.\n"]}]},{"cell_type":"code","source":["# DIAGNOSTIC SCRIPT - Let's see the actual JSON structure\n","import json\n","import os\n","\n","BASE_PATH = \"/content/drive/My Drive/Edge_AI_Project/models/tfjs_models\"\n","\n","def diagnose_model_json(model_name):\n","    \"\"\"\n","    Examine the actual structure of the model.json file\n","    \"\"\"\n","    model_json_path = os.path.join(BASE_PATH, model_name, 'model.json')\n","\n","    print(f\"\\n{'='*50}\")\n","    print(f\"üîç DIAGNOSING {model_name.upper()} MODEL\")\n","    print(f\"{'='*50}\")\n","\n","    if not os.path.exists(model_json_path):\n","        print(f\"‚ùå File not found: {model_json_path}\")\n","        return\n","\n","    with open(model_json_path, 'r') as f:\n","        model_config = json.load(f)\n","\n","    print(f\"üìÅ File exists: {model_json_path}\")\n","    print(f\"üìä File size: {os.path.getsize(model_json_path)} bytes\")\n","\n","    # Show top-level structure\n","    print(f\"\\nüèóÔ∏è  TOP-LEVEL STRUCTURE:\")\n","    for key in model_config.keys():\n","        print(f\"   - {key}\")\n","\n","    # Examine modelTopology structure\n","    if 'modelTopology' in model_config:\n","        print(f\"\\nüß† MODEL TOPOLOGY STRUCTURE:\")\n","        topology = model_config['modelTopology']\n","        for key in topology.keys():\n","            print(f\"   - {key}\")\n","\n","        # Look for model_config\n","        if 'model_config' in topology:\n","            print(f\"\\n‚öôÔ∏è  MODEL CONFIG STRUCTURE:\")\n","            model_cfg = topology['model_config']\n","            for key in model_cfg.keys():\n","                print(f\"   - {key}\")\n","\n","            # Look for layers\n","            if 'config' in model_cfg and 'layers' in model_cfg['config']:\n","                layers = model_cfg['config']['layers']\n","                print(f\"\\nüîó LAYERS FOUND: {len(layers)} layers\")\n","\n","                # Show first few layers\n","                for i, layer in enumerate(layers[:3]):\n","                    print(f\"\\n   Layer {i}: {layer.get('class_name', 'Unknown')}\")\n","                    print(f\"   Config keys: {list(layer.get('config', {}).keys())}\")\n","\n","                    # Check for input shape info\n","                    config = layer.get('config', {})\n","                    for shape_key in ['batch_input_shape', 'input_shape', 'shape']:\n","                        if shape_key in config:\n","                            print(f\"   ‚úÖ Found {shape_key}: {config[shape_key]}\")\n","                        else:\n","                            print(f\"   ‚ùå Missing {shape_key}\")\n","            else:\n","                print(f\"‚ùå No layers found in expected location\")\n","    else:\n","        print(f\"‚ùå No modelTopology found\")\n","\n","    # Show a small sample of the raw JSON\n","    print(f\"\\nüìù FIRST 500 CHARACTERS OF JSON:\")\n","    with open(model_json_path, 'r') as f:\n","        content = f.read()\n","        print(content[:500] + \"...\")\n","\n","# Diagnose all models\n","models = ['age', 'gender', 'emotion']\n","\n","for model_name in models:\n","    diagnose_model_json(model_name)\n","\n","print(f\"\\n\" + \"=\"*70)\n","print(f\"üéØ DIAGNOSTIC COMPLETE\")\n","print(f\"=\"*70)\n","print(f\"This will show us the EXACT structure so we can fix it properly!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_BUEuxcl_Sm","executionInfo":{"status":"ok","timestamp":1754218890026,"user_tz":-60,"elapsed":46,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"e74d7f50-85a1-4454-e823-50096b98df50"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","==================================================\n","üîç DIAGNOSING AGE MODEL\n","==================================================\n","üìÅ File exists: /content/drive/My Drive/Edge_AI_Project/models/tfjs_models/age/model.json\n","üìä File size: 356570 bytes\n","\n","üèóÔ∏è  TOP-LEVEL STRUCTURE:\n","   - format\n","   - generatedBy\n","   - convertedBy\n","   - modelTopology\n","   - weightsManifest\n","\n","üß† MODEL TOPOLOGY STRUCTURE:\n","   - keras_version\n","   - backend\n","   - model_config\n","   - training_config\n","\n","‚öôÔ∏è  MODEL CONFIG STRUCTURE:\n","   - class_name\n","   - config\n","\n","üîó LAYERS FOUND: 156 layers\n","\n","   Layer 0: InputLayer\n","   Config keys: ['batch_shape', 'dtype', 'sparse', 'name', 'batch_input_shape']\n","   ‚úÖ Found batch_input_shape: [None, 224, 224, 3]\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","   Layer 1: Conv2D\n","   Config keys: ['name', 'trainable', 'dtype', 'filters', 'kernel_size', 'strides', 'padding', 'data_format', 'dilation_rate', 'groups', 'activation', 'use_bias', 'kernel_initializer', 'bias_initializer', 'kernel_regularizer', 'bias_regularizer', 'activity_regularizer', 'kernel_constraint', 'bias_constraint']\n","   ‚ùå Missing batch_input_shape\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","   Layer 2: BatchNormalization\n","   Config keys: ['name', 'trainable', 'dtype', 'axis', 'momentum', 'epsilon', 'center', 'scale', 'beta_initializer', 'gamma_initializer', 'moving_mean_initializer', 'moving_variance_initializer', 'beta_regularizer', 'gamma_regularizer', 'beta_constraint', 'gamma_constraint', 'synchronized']\n","   ‚ùå Missing batch_input_shape\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","üìù FIRST 500 CHARACTERS OF JSON:\n","{\n","  \"format\": \"layers-model\",\n","  \"generatedBy\": \"keras v3.8.0\",\n","  \"convertedBy\": \"TensorFlow.js Converter v4.22.0\",\n","  \"modelTopology\": {\n","    \"keras_version\": \"3.8.0\",\n","    \"backend\": \"tensorflow\",\n","    \"model_config\": {\n","      \"class_name\": \"Functional\",\n","      \"config\": {\n","        \"name\": \"functional\",\n","        \"trainable\": true,\n","        \"layers\": [\n","          {\n","            \"class_name\": \"InputLayer\",\n","            \"config\": {\n","              \"batch_shape\": [\n","                null,\n","                224,\n","    ...\n","\n","==================================================\n","üîç DIAGNOSING GENDER MODEL\n","==================================================\n","üìÅ File exists: /content/drive/My Drive/Edge_AI_Project/models/tfjs_models/gender/model.json\n","üìä File size: 356570 bytes\n","\n","üèóÔ∏è  TOP-LEVEL STRUCTURE:\n","   - format\n","   - generatedBy\n","   - convertedBy\n","   - modelTopology\n","   - weightsManifest\n","\n","üß† MODEL TOPOLOGY STRUCTURE:\n","   - keras_version\n","   - backend\n","   - model_config\n","   - training_config\n","\n","‚öôÔ∏è  MODEL CONFIG STRUCTURE:\n","   - class_name\n","   - config\n","\n","üîó LAYERS FOUND: 156 layers\n","\n","   Layer 0: InputLayer\n","   Config keys: ['batch_shape', 'dtype', 'sparse', 'name', 'batch_input_shape']\n","   ‚úÖ Found batch_input_shape: [None, 224, 224, 3]\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","   Layer 1: Conv2D\n","   Config keys: ['name', 'trainable', 'dtype', 'filters', 'kernel_size', 'strides', 'padding', 'data_format', 'dilation_rate', 'groups', 'activation', 'use_bias', 'kernel_initializer', 'bias_initializer', 'kernel_regularizer', 'bias_regularizer', 'activity_regularizer', 'kernel_constraint', 'bias_constraint']\n","   ‚ùå Missing batch_input_shape\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","   Layer 2: BatchNormalization\n","   Config keys: ['name', 'trainable', 'dtype', 'axis', 'momentum', 'epsilon', 'center', 'scale', 'beta_initializer', 'gamma_initializer', 'moving_mean_initializer', 'moving_variance_initializer', 'beta_regularizer', 'gamma_regularizer', 'beta_constraint', 'gamma_constraint', 'synchronized']\n","   ‚ùå Missing batch_input_shape\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","üìù FIRST 500 CHARACTERS OF JSON:\n","{\n","  \"format\": \"layers-model\",\n","  \"generatedBy\": \"keras v3.8.0\",\n","  \"convertedBy\": \"TensorFlow.js Converter v4.22.0\",\n","  \"modelTopology\": {\n","    \"keras_version\": \"3.8.0\",\n","    \"backend\": \"tensorflow\",\n","    \"model_config\": {\n","      \"class_name\": \"Functional\",\n","      \"config\": {\n","        \"name\": \"functional\",\n","        \"trainable\": true,\n","        \"layers\": [\n","          {\n","            \"class_name\": \"InputLayer\",\n","            \"config\": {\n","              \"batch_shape\": [\n","                null,\n","                224,\n","    ...\n","\n","==================================================\n","üîç DIAGNOSING EMOTION MODEL\n","==================================================\n","üìÅ File exists: /content/drive/My Drive/Edge_AI_Project/models/tfjs_models/emotion/model.json\n","üìä File size: 20004 bytes\n","\n","üèóÔ∏è  TOP-LEVEL STRUCTURE:\n","   - format\n","   - generatedBy\n","   - convertedBy\n","   - modelTopology\n","   - weightsManifest\n","\n","üß† MODEL TOPOLOGY STRUCTURE:\n","   - keras_version\n","   - backend\n","   - model_config\n","   - training_config\n","\n","‚öôÔ∏è  MODEL CONFIG STRUCTURE:\n","   - class_name\n","   - config\n","\n","üîó LAYERS FOUND: 9 layers\n","\n","   Layer 0: InputLayer\n","   Config keys: ['batch_shape', 'dtype', 'sparse', 'name', 'batch_input_shape']\n","   ‚úÖ Found batch_input_shape: [None, 48, 48, 1]\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","   Layer 1: Conv2D\n","   Config keys: ['name', 'trainable', 'dtype', 'filters', 'kernel_size', 'strides', 'padding', 'data_format', 'dilation_rate', 'groups', 'activation', 'use_bias', 'kernel_initializer', 'bias_initializer', 'kernel_regularizer', 'bias_regularizer', 'activity_regularizer', 'kernel_constraint', 'bias_constraint']\n","   ‚ùå Missing batch_input_shape\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","   Layer 2: BatchNormalization\n","   Config keys: ['name', 'trainable', 'dtype', 'axis', 'momentum', 'epsilon', 'center', 'scale', 'beta_initializer', 'gamma_initializer', 'moving_mean_initializer', 'moving_variance_initializer', 'beta_regularizer', 'gamma_regularizer', 'beta_constraint', 'gamma_constraint', 'synchronized']\n","   ‚ùå Missing batch_input_shape\n","   ‚ùå Missing input_shape\n","   ‚ùå Missing shape\n","\n","üìù FIRST 500 CHARACTERS OF JSON:\n","{\n","  \"format\": \"layers-model\",\n","  \"generatedBy\": \"keras v3.8.0\",\n","  \"convertedBy\": \"TensorFlow.js Converter v4.22.0\",\n","  \"modelTopology\": {\n","    \"keras_version\": \"3.8.0\",\n","    \"backend\": \"tensorflow\",\n","    \"model_config\": {\n","      \"class_name\": \"Functional\",\n","      \"config\": {\n","        \"name\": \"functional_1\",\n","        \"trainable\": true,\n","        \"layers\": [\n","          {\n","            \"class_name\": \"InputLayer\",\n","            \"config\": {\n","              \"batch_shape\": [\n","                null,\n","                48,\n","   ...\n","\n","======================================================================\n","üéØ DIAGNOSTIC COMPLETE\n","======================================================================\n","This will show us the EXACT structure so we can fix it properly!\n"]}]},{"cell_type":"code","source":["# Simple verification - just check if TensorFlow.js can read the models\n","import json\n","import os\n","\n","BASE_PATH = \"/content/drive/My Drive/Edge_AI_Project/models/tfjs_models\"\n","\n","for model_name in ['age', 'gender', 'emotion']:\n","    model_json_path = os.path.join(BASE_PATH, model_name, 'model.json')\n","\n","    with open(model_json_path, 'r') as f:\n","        model_config = json.load(f)\n","\n","    # Check the first layer\n","    first_layer = model_config['modelTopology']['model_config']['config']['layers'][0]\n","    batch_shape = first_layer['config']['batch_input_shape']\n","\n","    print(f\"‚úÖ {model_name}: {batch_shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfuZF_lpmyWH","executionInfo":{"status":"ok","timestamp":1754219098506,"user_tz":-60,"elapsed":44,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"dfa88560-6f56-4069-a525-468e3a3cfe53"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ age: [None, 224, 224, 3]\n","‚úÖ gender: [None, 224, 224, 3]\n","‚úÖ emotion: [None, 48, 48, 1]\n"]}]},{"cell_type":"code","source":["#  Download the newly converted models\n","import shutil\n","import os\n","\n","# Zip the converted models for easy download\n","shutil.make_archive('/content/fixed_tfjs_models', 'zip', '/content/drive/My Drive/Edge_AI_Project/models/tfjs_models')\n","\n","print(\"‚úÖ Models zipped! Download from:\")\n","print(\"/content/fixed_tfjs_models.zip\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FIcCMExPdExi","executionInfo":{"status":"ok","timestamp":1754217672558,"user_tz":-60,"elapsed":2247,"user":{"displayName":"L L Berkley","userId":"09256118485292110051"}},"outputId":"0288ff1f-950b-4b99-be21-b577f86b2822"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Models zipped! Download from:\n","/content/fixed_tfjs_models.zip\n"]}]}]}